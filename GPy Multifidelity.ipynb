{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electoral-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-conservative",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acquired-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_H(x):\n",
    "    return(6.0*x-2.0)**2 * np.sin(12.0*x-4.0)\n",
    "\n",
    "def f_L(x):\n",
    "    return 0.5*f_H(x) + 10.0*(x-0.5) - 5.0\n",
    "\n",
    "def Normalize(X, X_m, X_s):\n",
    "    return (X-X_m) / (X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hired-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_H = 3\n",
    "N_L = 8\n",
    "D   = 1\n",
    "\n",
    "lb = 0.0\n",
    "ub = 1.0\n",
    "noise_L = 0.00\n",
    "noise_H = 0.00\n",
    "\n",
    "# Training data\n",
    "X_L = np.random.uniform(lb,ub, size = (N_L,1))\n",
    "y_L = f_L(X_L) + noise_L*np.random.randn(N_L,D)\n",
    "\n",
    "X_H = np.random.uniform(lb,ub, size = (N_H,1))\n",
    "y_H = f_H(X_H) + noise_H*np.random.randn(N_H,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial-remains",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters GP_regression.Gaussian_noise.variance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/20, f = 11.529961940634857\n",
      "Optimization restart 2/20, f = 18.325776776243302\n",
      "Optimization restart 3/20, f = 18.32577677479371\n",
      "Optimization restart 4/20, f = 18.3257767748015\n",
      "Optimization restart 5/20, f = 18.32577677478043\n",
      "Optimization restart 6/20, f = 18.325776775353166\n",
      "Optimization restart 7/20, f = 18.325776774783257\n",
      "Optimization restart 8/20, f = 18.3257767747815\n",
      "Optimization restart 9/20, f = 18.32577677482623\n",
      "Optimization restart 10/20, f = 18.3257767751417\n",
      "Optimization restart 11/20, f = 18.325776774858365\n",
      "Optimization restart 12/20, f = 18.325776774788036\n",
      "Optimization restart 13/20, f = 18.325776774782405\n",
      "Optimization restart 14/20, f = 18.325776774780046\n",
      "Optimization restart 15/20, f = 18.325776774780795\n",
      "Optimization restart 16/20, f = 18.325776774800325\n",
      "Optimization restart 17/20, f = 18.325776774779442\n",
      "Optimization restart 18/20, f = 18.32577677551057\n",
      "Optimization restart 19/20, f = 18.325776774833365\n",
      "Optimization restart 20/20, f = 18.325776775233045\n"
     ]
    }
   ],
   "source": [
    "kernel1 = GPy.kern.RBF(1)\n",
    "\n",
    "# Train the low fidelity\n",
    "m1 = GPy.models.GPRegression(X=X_L, Y=y_L, kernel=kernel1)\n",
    "\n",
    "m1[\".*Gaussian_noise\"] = m1.Y.var()*0.01\n",
    "m1[\".*Gaussian_noise\"].fix()\n",
    "\n",
    "m1.optimize(max_iters = 500)\n",
    "\n",
    "m1[\".*Gaussian_noise\"].unfix()\n",
    "m1[\".*Gaussian_noise\"].constrain_positive()\n",
    "\n",
    "# Restart optimization to find the global minimum instead of a local one\n",
    "m1.optimize_restarts(20, optimizer = \"bfgs\",  max_iters = 1000)\n",
    "\n",
    "mu1, v1 = m1.predict(X_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "binding-swedish",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'KernCallsViaSlicerMeta' and 'KernCallsViaSlicerMeta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2a652884e79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the higher fidelity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkernel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBias\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mGPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBias\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mGPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRBF\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRBF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mXX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'KernCallsViaSlicerMeta' and 'KernCallsViaSlicerMeta'"
     ]
    }
   ],
   "source": [
    "# Train the higher fidelity\n",
    "kernel2 = GPy.kern.Bias * GPy.kern.Bias * GPy.kern.RBF + GPy.kern.RBF\n",
    "XX = np.hstack((X_H,mu1))\n",
    "\n",
    "m2 = GPy.models.GPRegression(X=XX, Y=y_H, kernel=kernel2)\n",
    "\n",
    "m2[\".*Gaussian_noise\"] = m2.Y.var()*0.01\n",
    "m2[\".*Gaussian_noise\"].fix()\n",
    "\n",
    "m2.optimize(max_iters = 500)\n",
    "\n",
    "m2[\".*Gaussian_noise\"].unfix()\n",
    "m2[\".*Gaussian_noise\"].constrain_positive()\n",
    "\n",
    "# Restart optimization to find the global minimum instead of a local one\n",
    "m2.optimize_restarts(20, optimizer = \"bfgs\",  max_iters = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-syntax",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
